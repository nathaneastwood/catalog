[{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Nathan Eastwood. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Eastwood N (2022). catalog: Access 'Spark Catalog' API via 'sparklyr'. https://nathaneastwood.github.io/catalog/, https://github.com/nathaneastwood/catalog.","code":"@Manual{,   title = {catalog: Access the 'Spark Catalog' API via 'sparklyr'},   author = {Nathan Eastwood},   year = {2022},   note = {https://nathaneastwood.github.io/catalog/, https://github.com/nathaneastwood/catalog}, }"},{"path":"/contributing.html","id":null,"dir":"","previous_headings":"","what":"Contributing","title":"Contributing","text":"Contributions via GitHub pull requests gladly accepted original author. participating project, agree abide thoughtbot code conduct. Licensing R Coding Standards git Commit Standards pull request template guide expected pull request project.","code":""},{"path":"/contributing.html","id":"-licensing","dir":"","previous_headings":"","what":"Licensing","title":"Contributing","text":"Along pull requests, please state contribution original work license work project project’s open source license. Whether state explicitly, submitting copyrighted material via pull request, email, means agree license material project’s open source license warrant legal authority .","code":""},{"path":"/contributing.html","id":"-r-coding-standards","dir":"","previous_headings":"","what":"R Coding Standards","title":"Contributing","text":"follow style guide maintained within tidyverse. tested using lintr package; can automatically conform code standards using styler package. Please quality integers L, e.g. 1L.","code":""},{"path":"/contributing.html","id":"-git-commit-standards","dir":"","previous_headings":"","what":"git Commit Standards","title":"Contributing","text":"follow commit message style guide maintained within angular.js project. start commit messages must one following: feat: new feature fix: bug fix doc: Documentation changes style: Changes affect meaning code (white-space, formatting, missing semi-colons, etc) refactor: code change neither fixes bug adds feature perf: code change improves performance test: Adding missing tests chore: Changes build process auxiliary tools libraries documentation generation capitalise first letter.","code":""},{"path":[]},{"path":"/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Access the Spark Catalog API via sparklyr","text":"{catalog} gives user access Spark Catalog API making use {sparklyr} API. Catalog interface managing metastore (aka metadata catalog) relational entities (e.g. database(s), tables, functions, table columns temporary views).","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Access the Spark Catalog API via sparklyr","text":"can install: development version GitHub latest release CRAN ","code":"# install.packages(\"remotes\") remotes::install_github(\"nathaneastwood/catalog\") install.packages(\"catalog\")"},{"path":"/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Access the Spark Catalog API via sparklyr","text":"{catalog} provides API matching Catalog API provides full access methods. small example functionality. information, please refer package website.","code":"sc <- sparklyr::spark_connect(master = \"local\") mtcars_spark <- sparklyr::copy_to(dest = sc, df = mtcars)  library(catalog)  list_tables(sc) # # A tibble: 1 × 5 #   name   database description tableType isTemporary #   <chr>  <chr>    <chr>       <chr>     <lgl>       # 1 mtcars <NA>     <NA>        TEMPORARY TRUE  list_columns(sc, \"mtcars\") # # A tibble: 11 × 6 #    name  description dataType nullable isPartition isBucket #    <chr> <chr>       <chr>    <lgl>    <lgl>       <lgl>    #  1 mpg   <NA>        double   TRUE     FALSE       FALSE    #  2 cyl   <NA>        double   TRUE     FALSE       FALSE    #  3 disp  <NA>        double   TRUE     FALSE       FALSE    #  4 hp    <NA>        double   TRUE     FALSE       FALSE    #  5 drat  <NA>        double   TRUE     FALSE       FALSE    #  6 wt    <NA>        double   TRUE     FALSE       FALSE    #  7 qsec  <NA>        double   TRUE     FALSE       FALSE    #  8 vs    <NA>        double   TRUE     FALSE       FALSE    #  9 am    <NA>        double   TRUE     FALSE       FALSE    # 10 gear  <NA>        double   TRUE     FALSE       FALSE    # 11 carb  <NA>        double   TRUE     FALSE       FALSE  list_functions(sc) # # A tibble: 349 × 5 #    name  database description className                                  isTem…¹ #    <chr> <chr>    <chr>       <chr>                                      <lgl>   #  1 !     <NA>     <NA>        org.apache.spark.sql.catalyst.expressions… TRUE    #  2 %     <NA>     <NA>        org.apache.spark.sql.catalyst.expressions… TRUE    #  3 &     <NA>     <NA>        org.apache.spark.sql.catalyst.expressions… TRUE    #  4 *     <NA>     <NA>        org.apache.spark.sql.catalyst.expressions… TRUE    #  5 +     <NA>     <NA>        org.apache.spark.sql.catalyst.expressions… TRUE    #  6 -     <NA>     <NA>        org.apache.spark.sql.catalyst.expressions… TRUE    #  7 /     <NA>     <NA>        org.apache.spark.sql.catalyst.expressions… TRUE    #  8 <     <NA>     <NA>        org.apache.spark.sql.catalyst.expressions… TRUE    #  9 <=    <NA>     <NA>        org.apache.spark.sql.catalyst.expressions… TRUE    # 10 <=>   <NA>     <NA>        org.apache.spark.sql.catalyst.expressions… TRUE    # # … with 339 more rows, and abbreviated variable name ¹​isTemporary # # ℹ Use `print(n = ...)` to see more rows  drop_temp_view(sc, \"mtcars\") # [1] TRUE"},{"path":"/pull_request_template.html","id":"pull-request-template","dir":"","previous_headings":"","what":"Pull Request Template","title":"NA","text":"Please, go steps submit PR. Please make sure : made changes separate branch. Branches MUST descriptive names start either fix/, feat/ refactor/ prefixes (similar git guidelines project). Good examples : fix/mutate feat/arrange. descriptive commit message short title (first line). commit message follows git commit standards repository. one commit (, squash one commit). tinytest::test_all() throw errors. added new necessary tests test fix new feature. steps, ’re ready open pull request. Give descriptive title PR. Provide description changes. Put Closes #XXXX (Fixes #XXXX) comment auto-close issue PR introduces new feature (fixes), . IMPORTANT: Please review contributing.md file detailed contributing guidelines. PLEASE REMOVE TEMPLATE SUBMITTING","code":""},{"path":"/reference/cache_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Cache And Uncache Tables — cache_table","title":"Cache And Uncache Tables — cache_table","text":"Spark SQL can cache tables using -memory columnar format calling cache_table(). Spark SQL scan required columns automatically tune compression minimize memory usage GC pressure. can call uncache_table() remove table memory. Similarly can call clear_cache() remove cached tables -memory cache. Finally, use is_cached() test whether table cached.","code":""},{"path":"/reference/cache_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cache And Uncache Tables — cache_table","text":"","code":"cache_table(sc, table)  clear_cache(sc)  is_cached(sc, table)  uncache_table(sc, table)"},{"path":"/reference/cache_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cache And Uncache Tables — cache_table","text":"sc spark_connection. table character(1). name table.","code":""},{"path":"/reference/cache_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cache And Uncache Tables — cache_table","text":"cache_table(): successful, TRUE, otherwise FALSE. clear_cache(): NULL, invisibly. is_cached(): logical(1) vector indicating TRUE table cached FALSE otherwise. uncache_table(): NULL, invisibly.","code":""},{"path":[]},{"path":"/reference/cache_table.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cache And Uncache Tables — cache_table","text":"","code":"if (FALSE) { sc <- sparklyr::spark_connect(master = \"local\") mtcars_spark <- sparklyr::copy_to(dest = sc, df = mtcars)  # By default the table is not cached is_cached(sc = sc, table = \"mtcars\")  # We can manually cache the table cache_table(sc = sc, table = \"mtcars\") # And now the table is cached is_cached(sc = sc, table = \"mtcars\")  # We can uncache the table uncache_table(sc = sc, table = \"mtcars\") is_cached(sc = sc, table = \"mtcars\") }"},{"path":"/reference/create_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Create A Table — create_table","title":"Create A Table — create_table","text":"Creates table, hive warehouse, given path returns corresponding DataFrame. table contain contents file path parameter.","code":""},{"path":"/reference/create_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create A Table — create_table","text":"","code":"create_table(sc, table, path, source, ...)"},{"path":"/reference/create_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create A Table — create_table","text":"sc spark_connection. table character(1). name table create. path character(1). path use create table. source character(1). data source use create table \"parquet\", \"csv\", etc. ... Additional options passed createTable method.","code":""},{"path":"/reference/create_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create A Table — create_table","text":"tbl_spark.","code":""},{"path":"/reference/create_table.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create A Table — create_table","text":"default data source type parquet. can changed using source setting configuration option spark.sql.sources.default creating spark session using created session using","code":"config <- sparklyr::spark_config() config[[\"spark.sql.sources.default\"]] <- \"csv\""},{"path":[]},{"path":"/reference/current_database.html","id":null,"dir":"Reference","previous_headings":"","what":"Get The Current Database — current_database","title":"Get The Current Database — current_database","text":"Returns current database session. default session connected \"default\" database (named \"default\") change database can use set_current_database().","code":""},{"path":"/reference/current_database.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get The Current Database — current_database","text":"","code":"current_database(sc)"},{"path":"/reference/current_database.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get The Current Database — current_database","text":"sc spark_connection.","code":""},{"path":"/reference/current_database.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get The Current Database — current_database","text":"character(1), current database name.","code":""},{"path":[]},{"path":"/reference/current_database.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get The Current Database — current_database","text":"","code":"if (FALSE) { sc <- sparklyr::spark_connect(master = \"local\") current_database(sc = sc) }"},{"path":"/reference/database_exists.html","id":null,"dir":"Reference","previous_headings":"","what":"Check If A Database Exists — database_exists","title":"Check If A Database Exists — database_exists","text":"Check database specified name exists. check list hive databases current session see database exists.","code":""},{"path":"/reference/database_exists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check If A Database Exists — database_exists","text":"","code":"database_exists(sc, name)"},{"path":"/reference/database_exists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check If A Database Exists — database_exists","text":"sc spark_connection. name character(1). name database set current database .","code":""},{"path":"/reference/database_exists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check If A Database Exists — database_exists","text":"logical(1) vector indicating TRUE database exists FALSE otherwise.","code":""},{"path":[]},{"path":"/reference/database_exists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check If A Database Exists — database_exists","text":"","code":"if (FALSE) { sc <- sparklyr::spark_connect(master = \"local\") database_exists(sc = sc, name = \"default\") database_exists(sc = sc, name = \"fake_database\") }"},{"path":"/reference/drop_global_temp_view.html","id":null,"dir":"Reference","previous_headings":"","what":"Temporary View — drop_global_temp_view","title":"Temporary View — drop_global_temp_view","text":"drop_global_temp_view(): Drops global temporary view given view name catalog. drop_temp_view(): Drops local temporary view given view name catalog. Local temporary view session-scoped. lifetime lifetime session created , .e. automatically dropped session terminates. tied databases.","code":""},{"path":"/reference/drop_global_temp_view.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Temporary View — drop_global_temp_view","text":"","code":"drop_global_temp_view(sc, view)  drop_temp_view(sc, view)"},{"path":"/reference/drop_global_temp_view.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Temporary View — drop_global_temp_view","text":"sc spark_connection. view character(1). name temporary view dropped.","code":""},{"path":"/reference/drop_global_temp_view.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Temporary View — drop_global_temp_view","text":"logical(1) vector indicating whether temporary view dropped (TRUE) (FALSE).","code":""},{"path":[]},{"path":"/reference/drop_global_temp_view.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Temporary View — drop_global_temp_view","text":"","code":"if (FALSE) { sc <- sparklyr::spark_connect(master = \"local\") mtcars_spark <- sparklyr::copy_to(dest = sc, df = mtcars)  # We can check which temporary tables are in scope list_tables(sc = sc)  # And then drop those we wish to drop drop_temp_view(sc = sc, view = \"mtcars\") }"},{"path":"/reference/function_exists.html","id":null,"dir":"Reference","previous_headings":"","what":"Check If A Function Exists — function_exists","title":"Check If A Function Exists — function_exists","text":"Check function specified name exists specified database.","code":""},{"path":"/reference/function_exists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check If A Function Exists — function_exists","text":"","code":"function_exists(sc, fn, database = NULL)"},{"path":"/reference/function_exists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check If A Function Exists — function_exists","text":"sc spark_connection. fn character(1). name function. database character(1). name database functions listed (default: NULL).","code":""},{"path":"/reference/function_exists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check If A Function Exists — function_exists","text":"logical(1) vector indicating TRUE function exists within specified database FALSE otherwise.","code":""},{"path":"/reference/function_exists.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check If A Function Exists — function_exists","text":"function_exists() includes -built functions abs. see built-function exists must use unqualified name. create function can use qualified name. want check built-function exists specify database NULL.","code":""},{"path":"/reference/function_exists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check If A Function Exists — function_exists","text":"","code":"if (FALSE) { sc <- sparklyr::spark_connect(master = \"local\") function_exists(sc = sc, fn = \"abs\") }"},{"path":"/reference/get_function.html","id":null,"dir":"Reference","previous_headings":"","what":"Get A Function — get_function","title":"Get A Function — get_function","text":"Get function specified name.","code":""},{"path":"/reference/get_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get A Function — get_function","text":"","code":"get_function(sc, fn, database = NULL)"},{"path":"/reference/get_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get A Function — get_function","text":"sc spark_connection. fn character(1). name function. database character(1). name database functions listed (default: NULL).","code":""},{"path":"/reference/get_function.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get A Function — get_function","text":"spark_jobj includes class name, database, description, whether temporary name function.","code":""},{"path":"/reference/get_function.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get A Function — get_function","text":"trying get -built function use unqualified name pass NULL database name.","code":""},{"path":[]},{"path":"/reference/get_function.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get A Function — get_function","text":"","code":"if (FALSE) { sc <- sparklyr::spark_connect(master = \"local\") get_function(sc = sc, fn = \"Not\") }"},{"path":"/reference/get_table.html","id":null,"dir":"Reference","previous_headings":"","what":"Get A Table — get_table","title":"Get A Table — get_table","text":"Get table view specified name specified database. can use find table's description, database, type whether temporary table .","code":""},{"path":"/reference/get_table.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get A Table — get_table","text":"","code":"get_table(sc, table, database = NULL)"},{"path":"/reference/get_table.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get A Table — get_table","text":"sc spark_connection. table character(1). name table. database character(1). name database functions listed (default: NULL).","code":""},{"path":"/reference/get_table.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get A Table — get_table","text":"object class spark_jobj shell_jobj.","code":""},{"path":[]},{"path":"/reference/list_columns.html","id":null,"dir":"Reference","previous_headings":"","what":"List Columns — list_columns","title":"List Columns — list_columns","text":"Returns list columns given table/view specified database. result includes name, description, dataType, whether nullable partitioned broken buckets.","code":""},{"path":"/reference/list_columns.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List Columns — list_columns","text":"","code":"list_columns(sc, table, database = NULL)"},{"path":"/reference/list_columns.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List Columns — list_columns","text":"sc spark_connection. table character(1). name table. database character(1). name database functions listed (default: NULL).","code":""},{"path":"/reference/list_columns.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List Columns — list_columns","text":"tibble 6 columns: name - name column. description - Description column. dataType - column data type. nullable - Whether column nullable . isPartition - Whether column partitioned . isBucket - Whether column broken buckets.","code":""},{"path":"/reference/list_columns.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List Columns — list_columns","text":"","code":"if (FALSE) { sc <- sparklyr::spark_connect(master = \"local\") mtcars_spark <- sparklyr::copy_to(dest = sc, df = mtcars) list_columns(sc = sc, table = \"mtcars\") }"},{"path":"/reference/list_databases.html","id":null,"dir":"Reference","previous_headings":"","what":"List Databases — list_databases","title":"List Databases — list_databases","text":"Returns list databases available across sessions. result contains name, description locationUri database.","code":""},{"path":"/reference/list_databases.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List Databases — list_databases","text":"","code":"list_databases(sc)"},{"path":"/reference/list_databases.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List Databases — list_databases","text":"sc spark_connection.","code":""},{"path":"/reference/list_databases.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List Databases — list_databases","text":"tibble containing 3 columns: name - name database. description - Description database. locationUri - Path (form uri) data files.","code":""},{"path":[]},{"path":"/reference/list_databases.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List Databases — list_databases","text":"","code":"if (FALSE) { sc <- sparklyr::spark_connect(master = \"local\") list_databases(sc = sc) }"},{"path":"/reference/list_functions.html","id":null,"dir":"Reference","previous_headings":"","what":"List Functions — list_functions","title":"List Functions — list_functions","text":"Returns list functions registered specified database. includes temporary functions. result contains class name, database, description, whether temporary name function.","code":""},{"path":"/reference/list_functions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List Functions — list_functions","text":"","code":"list_functions(sc, database = NULL)"},{"path":"/reference/list_functions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List Functions — list_functions","text":"sc spark_connection. database character(1). name database functions listed (default: NULL).","code":""},{"path":"/reference/list_functions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List Functions — list_functions","text":"tibble containing 5 columns: name - Name function. database - Name database function belongs . description - Description function. className - fully qualified class name function. isTemporary - Whether function temporary .","code":""},{"path":[]},{"path":"/reference/list_functions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List Functions — list_functions","text":"","code":"if (FALSE) { sc <- sparklyr::spark_connect(master = \"local\") list_functions(sc = sc) list_functions(sc = sc, database = \"default\") }"},{"path":"/reference/list_tables.html","id":null,"dir":"Reference","previous_headings":"","what":"List Tables In A Spark Connection — list_tables","title":"List Tables In A Spark Connection — list_tables","text":"Returns list tables/views current database. result includes name, database, description, table type whether table temporary .","code":""},{"path":"/reference/list_tables.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"List Tables In A Spark Connection — list_tables","text":"","code":"list_tables(sc, database = NULL)"},{"path":"/reference/list_tables.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"List Tables In A Spark Connection — list_tables","text":"sc spark_connection. database character(1). name database functions listed (default: NULL).","code":""},{"path":"/reference/list_tables.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"List Tables In A Spark Connection — list_tables","text":"tibble containing 5 columns: name - name table. database - Name database table belongs . description - Description table. tableType - type table (e.g. view/table) isTemporary - Whether table temporary .","code":""},{"path":[]},{"path":"/reference/list_tables.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"List Tables In A Spark Connection — list_tables","text":"","code":"if (FALSE) { sc <- sparklyr::spark_connect(master = \"local\") mtcars_spakr <- sparklyr::copy_to(dest = sc, df = mtcars) list_tables(sc = sc) }"},{"path":"/reference/refresh.html","id":null,"dir":"Reference","previous_headings":"","what":"Refreshing Data — refresh","title":"Refreshing Data — refresh","text":"recover_partitions(): Recovers partitions directory table update catalog. works partitioned tables un-partitioned tables views. refresh_by_path(): Invalidates refreshes cached data (associated metadata) Dataset contains given data source path. Path matching prefix, .e. \"/\" invalidate everything cached. refresh_table(): Invalidates refreshes cached data metadata given table. performance reasons, Spark SQL external data source library uses might cache certain metadata table, location blocks. change outside Spark SQL, users call function invalidate cache. table cached InMemoryRelation, drop original cached version make new version cached lazily.","code":""},{"path":"/reference/refresh.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Refreshing Data — refresh","text":"","code":"recover_partitions(sc, table)  refresh_by_path(sc, path)  refresh_table(sc, table)"},{"path":"/reference/refresh.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Refreshing Data — refresh","text":"sc spark_connection. table character(1). name table. path character(1). path refresh.","code":""},{"path":"/reference/refresh.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Refreshing Data — refresh","text":"NULL, invisibly. functions mostly called side effects.","code":""},{"path":[]},{"path":"/reference/set_current_database.html","id":null,"dir":"Reference","previous_headings":"","what":"Set The Current Database — set_current_database","title":"Set The Current Database — set_current_database","text":"Sets current default database session.","code":""},{"path":"/reference/set_current_database.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set The Current Database — set_current_database","text":"","code":"set_current_database(sc, name)"},{"path":"/reference/set_current_database.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set The Current Database — set_current_database","text":"sc spark_connection. name character(1). name database set current database .","code":""},{"path":"/reference/set_current_database.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set The Current Database — set_current_database","text":"successful, TRUE, otherwise errors.","code":""},{"path":[]},{"path":"/reference/set_current_database.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Set The Current Database — set_current_database","text":"","code":"if (FALSE) { sc <- sparklyr::spark_connect(master = \"local\") set_current_database(sc = sc, name = \"new_db\") }"},{"path":"/reference/table_exists.html","id":null,"dir":"Reference","previous_headings":"","what":"Check If A Table Exists — table_exists","title":"Check If A Table Exists — table_exists","text":"Check table view specified name exists specified database. can either temporary view table/view.","code":""},{"path":"/reference/table_exists.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check If A Table Exists — table_exists","text":"","code":"table_exists(sc, table, database = NULL)"},{"path":"/reference/table_exists.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check If A Table Exists — table_exists","text":"sc spark_connection. table character(1). name table. database character(1). name database functions listed (default: NULL).","code":""},{"path":"/reference/table_exists.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check If A Table Exists — table_exists","text":"logical(1) vector indicating TRUE table exists within specified database FALSE otherwise.","code":""},{"path":"/reference/table_exists.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Check If A Table Exists — table_exists","text":"database NULL, table_exists refers table current database (see current_database()).","code":""},{"path":[]},{"path":"/reference/table_exists.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check If A Table Exists — table_exists","text":"","code":"if (FALSE) { sc <- sparklyr::spark_connect(master = \"local\") mtcars_spark <- sparklyr::copy_to(dest = sc, df = mtcars) table_exists(sc = sc, table = \"mtcars\") }"},{"path":"/news/index.html","id":"catalog-010","dir":"Changelog","previous_headings":"","what":"catalog 0.1.0","title":"catalog 0.1.0","text":"CRAN release: 2021-03-20 initial release {catalog} package. release adds full suite functionality Catalog API including: cache_table() clear_cache() is_cached() refresh_by_path() refresh_table() uncache_table() list_columns() current_database() database_exists() list_databases() set_current_database() function_exists() get_function() list_functions() recover_partitions() create_table() get_table() list_tables() table_exists() drop_global_temp_view() drop_temp_view()","code":""}]
